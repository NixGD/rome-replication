{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "from transformers.models.gpt2.tokenization_gpt2_fast import GPT2TokenizerFast\n",
    "\n",
    "from gpt import GPT2, load_weights\n",
    "from hook_handler import HookHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = load_weights(GPT2)\n",
    "gpt.eval();\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline completions\n",
      "' Paris'       6.37%\n",
      "' London'      4.61%\n",
      "' Amsterdam'   3.41%\n",
      "' New'         3.18%\n",
      "' Berlin'      2.61%\n"
     ]
    }
   ],
   "source": [
    "def most_likely(model_out, k=5):\n",
    "    target_probs = t.softmax(model_out.logits.squeeze(0), dim=0)\n",
    "    top_probs, top_ids = t.topk(target_probs, k=k)\n",
    "    for i in range(k):\n",
    "        token = tokenizer.decode(top_ids[i])\n",
    "        print(f\"{repr(token).ljust(15)}{top_probs[i]:.2%}\")\n",
    "\n",
    "with HookHandler() as hh:\n",
    "    for i, block in enumerate(gpt.blocks):\n",
    "        hh.add_save_activation_hook(block, key=i)\n",
    "\n",
    "    input_ids = tokenizer.encode(\"The Eiffel Tower is located in the city of\", return_tensors=\"pt\")\n",
    "    out = gpt(input_ids)\n",
    "    activations = hh.activations\n",
    "\n",
    "    print(\"Baseline completions\")\n",
    "    most_likely(gpt(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40313]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The' ' E' 'iff' 'el' ' Tower' 'is' ' located' ' in' ' the' ' city' ' of' \n",
      "0.04820826277136803\n"
     ]
    }
   ],
   "source": [
    "def get_correct_prob(out, correct_id):\n",
    "    return t.softmax(out.logits[0], dim=-1)[correct_id].item()\n",
    "\n",
    "\n",
    "def print_tokenized(ids):\n",
    "    l = tokenizer.batch_decode([[id] for id in ids])\n",
    "    for t in l:\n",
    "        print(repr(t), end=\" \")\n",
    "    print()\n",
    "\n",
    "\n",
    "def run_baseline(model, input_ids, correct_id):\n",
    "    with HookHandler() as hh:\n",
    "        for i, block in enumerate(model.blocks):\n",
    "            hh.add_save_activation_hook(block, key=i)\n",
    "\n",
    "        logits = model(input_ids)\n",
    "        correct_prob = get_correct_prob(logits, correct_id)\n",
    "        return hh.activations, correct_prob\n",
    "\n",
    "def avg_evaluate(model, input_ids, correct_id, k=5, **kwargs):\n",
    "    probs = []\n",
    "    seeds = range(k)\n",
    "    for seed in seeds:\n",
    "        t.manual_seed(seed)\n",
    "        corrupt_out = model.forward_corrupt_and_patch(\n",
    "            input_ids, **kwargs\n",
    "        )\n",
    "        probs.append(get_correct_prob(corrupt_out, correct_id))\n",
    "    return sum(probs)/k\n",
    "\n",
    "def patching(model: GPT2, tokenizer, subject, relation, target):\n",
    "    subject_ids = tokenizer.encode(subject, return_tensors=\"pt\")\n",
    "    relation_ids = tokenizer.encode(relation, return_tensors=\"pt\")\n",
    "    subj_len = subject_ids.shape[1]\n",
    "    input_ids = t.cat((subject_ids, relation_ids), dim=1)\n",
    "    print_tokenized(input_ids[0])\n",
    "    correct_id = tokenizer.encode(target)\n",
    "    assert len(correct_id) == 1\n",
    "    correct_id = correct_id[0]\n",
    "\n",
    "    activations, p_baseline = run_baseline(model, input_ids, correct_id)\n",
    "\n",
    "    print(p_baseline)\n",
    "\n",
    "    n_layers = len(model.blocks)\n",
    "    n_tokens = input_ids.shape[1]\n",
    "    avg_prob = np.zeros((n_tokens, n_layers))\n",
    "    for patch_token in range(n_tokens):\n",
    "        for layer in range(n_layers):\n",
    "            patch_value = activations[layer][0, patch_token]\n",
    "            prob = avg_evaluate(\n",
    "                model, input_ids=input_ids, correct_id=correct_id, k=3,\n",
    "                patch=True, patch_layer=layer, patch_value=patch_value, patch_id=patch_token,\n",
    "                corrupt=True, corrupt_up_to=subj_len, corrupt_noise_std=.1\n",
    "            )\n",
    "            avg_prob[patch_token, layer] = prob\n",
    "    return avg_prob\n",
    "\n",
    "probs = patching(gpt, tokenizer, \"The Eiffel Tower\", \"is located in the city of\", \" Paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x154ede820>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 314.182x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02436324, 0.0219464 , 0.02216303, 0.02210568, 0.02213864,\n",
       "        0.02211011, 0.02217013, 0.02220609, 0.0222077 , 0.02221264,\n",
       "        0.02217421, 0.02217815],\n",
       "       [0.02742387, 0.02511661, 0.02366233, 0.02321812, 0.0229683 ,\n",
       "        0.02304354, 0.02290683, 0.02285297, 0.0224273 , 0.02226189,\n",
       "        0.02227878, 0.02217815],\n",
       "       [0.03092285, 0.03076629, 0.03049103, 0.03024837, 0.03166145,\n",
       "        0.03233708, 0.02862963, 0.02714776, 0.02644857, 0.02268049,\n",
       "        0.0220969 , 0.02217815],\n",
       "       [0.02403027, 0.02531252, 0.02601109, 0.02486087, 0.02420756,\n",
       "        0.02007296, 0.02181539, 0.02190646, 0.02340199, 0.02274748,\n",
       "        0.02226583, 0.02217815],\n",
       "       [0.02661828, 0.02848907, 0.02964423, 0.03104737, 0.03228635,\n",
       "        0.03143164, 0.03041397, 0.02951983, 0.0261109 , 0.02301843,\n",
       "        0.02249195, 0.02217815],\n",
       "       [0.02296451, 0.02386267, 0.02299169, 0.0225172 , 0.02199822,\n",
       "        0.02252349, 0.02271045, 0.02320788, 0.0231623 , 0.02232462,\n",
       "        0.02219917, 0.02217815],\n",
       "       [0.02242437, 0.02271294, 0.02260925, 0.02264615, 0.02250552,\n",
       "        0.02288986, 0.02277154, 0.02269129, 0.02246642, 0.02223754,\n",
       "        0.02221829, 0.02217815],\n",
       "       [0.02262733, 0.02306268, 0.0230798 , 0.02305185, 0.02300157,\n",
       "        0.02348148, 0.02391154, 0.02391322, 0.0242654 , 0.02480979,\n",
       "        0.02412171, 0.02217815],\n",
       "       [0.02225488, 0.02233491, 0.02215855, 0.02229083, 0.02233959,\n",
       "        0.02238306, 0.02254757, 0.02244366, 0.02264983, 0.02281817,\n",
       "        0.02253364, 0.02217815],\n",
       "       [0.02186564, 0.02226191, 0.02211637, 0.02218438, 0.02264744,\n",
       "        0.02279624, 0.02347794, 0.0231044 , 0.02285432, 0.02254276,\n",
       "        0.02230629, 0.02217815],\n",
       "       [0.02215604, 0.02240325, 0.02319735, 0.02312602, 0.0229889 ,\n",
       "        0.02320304, 0.02369463, 0.02485417, 0.02706007, 0.03818798,\n",
       "        0.04300764, 0.04820826]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Zeroed out 'theory' token\")\n",
    "for i in range(12):\n",
    "    print(f\"on layer {i}\")\n",
    "    most_likely(gpt.forward_patched_activation(input_ids, 3, i, t.zeros(768)), k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65f90a54bef3c0d24f3b083491395768f5761cc8b5f4afc0423ab2e58fdb3112"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('rome': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
