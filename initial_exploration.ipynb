{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import warnings\n",
    "\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "from transformers.models.gpt2.tokenization_gpt2_fast import GPT2TokenizerFast\n",
    "\n",
    "from gpt import GPT2, get_pretrained_gpt, Corruption, Patch\n",
    "from hook_handler import HookHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2(\n",
       "  (token_embedding): Embedding(50257, 768)\n",
       "  (pos_embedding): Embedding(1024, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = get_pretrained_gpt()\n",
    "gpt.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The problem with modern culture is that it is an ongoing process which involves changing the way we think about things. It's not a new thing, but it's something that has been\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.generate(\"The problem with modern culture is\", temperature=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = load_weights(GPT2)\n",
    "gpt.eval();\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2(\n",
       "  (token_embedding): Embedding(50257, 768)\n",
       "  (pos_embedding): Embedding(1024, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): GPT2Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): UniAttention(\n",
       "        (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "print(f\"using {device}\")\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline completions\n",
      "' Paris'       6.37%\n",
      "' London'      4.61%\n",
      "' Amsterdam'   3.41%\n",
      "' New'         3.18%\n",
      "' Berlin'      2.61%\n"
     ]
    }
   ],
   "source": [
    "def most_likely(model_out, k=5):\n",
    "    target_probs = t.softmax(model_out.logits.squeeze(0), dim=0)\n",
    "    top_probs, top_ids = t.topk(target_probs, k=k)\n",
    "    for i in range(k):\n",
    "        token = tokenizer.decode(top_ids[i])\n",
    "        print(f\"{repr(token).ljust(15)}{top_probs[i]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fact = namedtuple(\"Fact\", ['subject', 'relation', 'object'])\n",
    "example_facts = [\n",
    "    Fact(\"Lawrence Taylor\", \" professionally plays the sport of\", \" football\"),\n",
    "    Fact(\"The Eiffle Tower\", \" is in the city of\", \" Paris\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "'Law' 'rence' ' Taylor' ' professionally' ' plays' ' the' ' sport' ' of' \n",
      "\n",
      "Prob ability of the correct answer (' football')\n",
      "normal gpt: 7.35%\n",
      "corrupted:  5.80%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_correct_prob(out, correct_id):\n",
    "    return t.softmax(out.logits[0], dim=-1)[correct_id].item()\n",
    "\n",
    "\n",
    "def print_tokenized(ids):\n",
    "    l = tokenizer.batch_decode([[id] for id in ids])\n",
    "    for t in l:\n",
    "        print(repr(t), end=\" \")\n",
    "    print()\n",
    "\n",
    "\n",
    "def run_baseline(model, input_ids, correct_id):\n",
    "    with HookHandler() as hh:\n",
    "        for i, block in enumerate(model.blocks):\n",
    "            hh.add_save_activation_hook(block, key=i)\n",
    "\n",
    "        logits = model(input_ids)\n",
    "        correct_prob = get_correct_prob(logits, correct_id)\n",
    "        return hh.activations, correct_prob\n",
    "\n",
    "\n",
    "def avg_evaluate(model, input_ids, correct_id, k=5, **kwargs):\n",
    "    probs = []\n",
    "    seeds = range(k)\n",
    "    for seed in seeds:\n",
    "        t.manual_seed(seed)\n",
    "        corrupt_out = model.forward_corrupt_and_patch(input_ids, **kwargs)\n",
    "        probs.append(get_correct_prob(corrupt_out, correct_id))\n",
    "    return sum(probs) / k\n",
    "\n",
    "\n",
    "def patching(\n",
    "    model: GPT2, tokenizer, fact: Fact, k=10, noise_std=0.2, plot=True\n",
    "):\n",
    "    if fact.relation[0] != \" \":\n",
    "        warnings.warn(f\"The fact relation {fact.relation} does not start with a space\")\n",
    "    if fact.object[0] != \" \":\n",
    "        warnings.warn(f\"The fact object {fact.object} does not start with a space\")\n",
    "\n",
    "    subject_ids = tokenizer.encode(fact.subject, return_tensors=\"pt\").to(device)\n",
    "    relation_ids = tokenizer.encode(fact.relation, return_tensors=\"pt\").to(device)\n",
    "    subj_len = subject_ids.shape[1]\n",
    "    input_ids = t.cat((subject_ids, relation_ids), dim=1)\n",
    "    correct_id = tokenizer.encode(fact.object)\n",
    "    if len(correct_id) != 1:\n",
    "        warnings.warn(\n",
    "            f\"The fact object {fact.object} is {len(correct_id)} tokens long, only using first token\"\n",
    "        )\n",
    "    correct_id = correct_id[0]\n",
    "\n",
    "    activations, p_baseline = run_baseline(model, input_ids, correct_id)\n",
    "\n",
    "    corruption = Corruption(subj_len, noise_std)\n",
    "    p_corrupted = avg_evaluate(\n",
    "        model,\n",
    "        input_ids=input_ids,\n",
    "        correct_id=correct_id,\n",
    "        k=k,\n",
    "        corruption=corruption,\n",
    "    )\n",
    "    \n",
    "    print(f\"Input:\")\n",
    "    print_tokenized(input_ids[0])\n",
    "\n",
    "    print(f\"\\nProb ability of the correct answer ({repr(fact.object)})\")\n",
    "    print(f\"normal gpt: {p_baseline:.2%}\")\n",
    "    print(f\"corrupted:  {p_corrupted:.2%}\")\n",
    "\n",
    "    n_layers = len(model.blocks)\n",
    "    n_tokens = input_ids.shape[1]\n",
    "    avg_prob = np.zeros((n_tokens, n_layers))\n",
    "    for token in range(n_tokens):\n",
    "        for layer in range(n_layers):\n",
    "            patch_value = activations[layer][0, token]\n",
    "            patch = Patch(token=token, layer=layer, value=patch_value)\n",
    "            prob = avg_evaluate(\n",
    "                model,\n",
    "                input_ids=input_ids,\n",
    "                correct_id=correct_id,\n",
    "                k=k,\n",
    "                patch=patch,\n",
    "                corruption=corruption,\n",
    "            )\n",
    "            avg_prob[token, layer] = prob\n",
    "\n",
    "    if plot:\n",
    "        plt.matshow(avg_prob, vmin=p_corrupted, vmax=p_baseline, cmap=\"Blues\")\n",
    "        l = tokenizer.batch_decode([[id] for id in input_ids[0]])\n",
    "        plt.yticks(ticks=range(n_tokens), labels=[repr(t) for t in l])\n",
    "        plt.xlabel(\"Single layer encoding is patched at\")\n",
    "        plt.gca().xaxis.set_label_position(\"top\")\n",
    "        plt.colorbar()\n",
    "    return avg_prob\n",
    "\n",
    "\n",
    "probs = patching(\n",
    "    gpt, tokenizer, example_facts[0], k=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65f90a54bef3c0d24f3b083491395768f5761cc8b5f4afc0423ab2e58fdb3112"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('rome': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
